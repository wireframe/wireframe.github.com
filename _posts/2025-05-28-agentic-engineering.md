---
title: "Agentic Engineering: Pilots Wanted"
tags:
- engineering
- product development
---

*Practical steps for integrating agents into your team, your stack, and your cultureâ€”without the hype*

## Buckle up!

Weâ€™re entering a new era of product development.

Agentsâ€”powered by large language models and other autonomous systemsâ€”are no longer just novelty tools or research demos. Theyâ€™re *rapidly* becoming part of the workforce. Whether itâ€™s triaging bugs, generating tests, or scaffolding new features, weâ€™re seeing agents embedded into the tools, platforms, and our daily workflows.

The differentiator isnâ€™t just in having agents. Itâ€™s in building the environment, infrastructure, and mindsets that allow teams to integrate them meaningfully.

But weâ€™re still in the early days, and teams are regularly stumbling over landmines: tooling is inconsistent, the behavior is brittle, hallucinations, stale context, unpredictable edge cases. Itâ€™s messy. Itâ€™s frustrating. And itâ€™s also one of **the most exciting shifts weâ€™ve seen in software** since the rise of cloud-native development.

In this moment of rapid technological shift, now more than ever, we need "Pilots"â€”those who proactively tune environments, validate outputs, and guide agents through complex systems. Not "Passengers" waiting for someone else to figure it all out.

Letâ€™s get to work.

---

## From Planning to Landing: Humans *still* required

Let's get this out of the way first. Agents currently have *severe* limitations and require significant oversight from domain experts with sufficient context. You cannot abdicate responsibility for code written by an agent. Theyâ€™re only following your instructionsâ€”you bear responsibility for the result.

[This excellent interview with Gumroad's CEO, Sahil Lavingia](https://youtu.be/KVZ3vMx_aJ4), describes a model of human + agent collaboration where humans act as the task planners and reviewersâ€”allowing agents to operate asynchronously.

Humans are uniquely suited to:

1. **The Planning.** Craft clear intent by providing well-defined tasks, expected outputs, and reference materials.
2. **The Landing.** Review, test, and ensure the agentâ€™s output meets quality and functional standards. This often involves the same rigor as traditional code review and QA.

Teams can begin evaluating agents not just by what they outputâ€”but by how much human intervention is needed to land that work safely.

## Agents as Interns

Think of an agent as an intern. Ask an intern to "optimize the UI" and youâ€™ll get chaos. But with a clear spec, metrics, and examples, youâ€™ll get useful output.

Todayâ€™s agents are confident but brittle. This model helps manage expectations: with structure and support, they can be effective contributors.

When working with an agent, ask yourself:

> ðŸ§  If it could help an intern, it **definitely** will help an agent.

This test ensures youâ€™re providing enough context and scaffolding for success.

(Side note: Itâ€™s wild to consider that **today is the worst these agents will ever be**. The pace of improvement is staggering.)

## Agent-Ready DX

If your systems are hard for humans to work with, theyâ€™re worse for machines. Great Developer Experience (DX) benefits everyoneâ€”including agents.

Make it easy for both:

* **Reproducible environments:** Use containers or setup scripts to onboard agents and humans alike.
* **Reliable test suites:** Fast, comprehensive tests allow agents to verify their changes.
* **Clear observability:** Well-structured logs, traces, and error messages help both sides of the collaboration debug effectively.

Better DX = more autonomy and less babysitting.

## It's All About the Context

Agents need usable context to succeed. In greenfield apps, itâ€™s easier to bake in modular design and modern practices from the start.

Legacy systems? Thatâ€™s where it gets tricky.

Use this **Agent Context Hygiene** checklist:

- âŒ Outdated or incomplete documentation  
- âŒ Accumulated TODOs and dead code  
- âŒ Inconsistent naming or structure  
- âœ… Modular, readable code  
- âœ… Accurate READMEs and internal docs

Poor context = hallucinations, misfires, and frustration. Fixing that helps everyone.

## Agentic Ecosystem

Thereâ€™s no universal agent. Choose tools that fit your use case and maturity.

### a. Rapid Prototyping Agents  
*e.g., Vercel V0, Lovable.ai*

Great for early exploration. These tools convert napkin sketches or high-level designs into clickable prototypes. Donâ€™t expect production-ready codeâ€”optimize for speed and learning.

### b. Engineering Implementation Agents  
*e.g., Cursor, GitHub Copilot, Devin.ai*

These work within your real stackâ€”leveraging your data models, APIs, and architecture.

> Start small. Use real workflows. Measure impact.

## The Future is Nowâ€¦

Agentic engineering isnâ€™t a shortcut. Itâ€™s a discipline. A mindset of designing systems that enable collaborationâ€”not just execution.

Teams that win wonâ€™t just adopt agents. Theyâ€™ll create the conditions for agents to thrive: tuned environments, clean codebases, strong oversight, and a culture that supports experimentation.

In this rapidly evolving space, one thing is clear:
**Pilots ~~wanted~~ required.**